# 概述
从多张不同焦距拍摄的IGBT图像中估测深度信息，是3D视觉中还原场景真实物理信息的重要部分，基础做法是改变焦距，利用对焦或者离焦的方式采集若干图像，然后计算图像梯度。一般来说，修正的Laplace算法，高斯插值等算法比较主流，但本质上都是对梯度图像进行插值运算，从而进行深度图重构，如果图像梯度出现极值，那么这个位置可能存在图像的高度极值，然后根据临近像素的关系，逐像素进行插值，从而还原深度图，也有采用多项式曲线插值，NURBS曲线插值等，但迭代时间太长，收敛误差不好控制，不建议使用。Gauss插值、Laplace插值、拉格朗日插值等效果较好。
# 做法
本项目一共采集107张IGBT图像，从中计算线高，还原深度信息，但实际上图像焦距的跳变比较严重，实际有效的图片得剔除前20张，所有图像均为8位深度。
本项目比较好的效果是用Python实现的Laplace算法，通过纠正偏差进行深度测算，最后采用高斯插值，还原深度信息。接着采用Halcon集成的DFF算子，这个版本速度更快，效果也较好。
然后基于C++，C#不同版本语言进行实现，算法大同小异，但实测Halcon速度更快，效果更好，还原的深度数据保存到excel文件中。
# 可优化点
如果我们的相机帧率足够高，且能够适配电控部分协同拍摄，短时内可以获得多张不同焦段的图像，且跳变不明显，即图像质量较好，其实可以不用做矫正，用中值滤波或者加权中值滤波滤除毛刺。
反之，可以考虑SIFT算法，因为其具有尺度不变性，较好的还原场景的全景图。或者用光流法，矫正相机的轴向视差。
# 参考
## 1.更多的实现方案
 >  ref (https://github.com/liZongYue123/DFF.git), python实现方案，耗时较长， 但精度可以。\
> ref (https://github.com/liZongYue123/DFF_RDF.git), matlab实现方案，最好硬件上内存足够大，因为我就爆内存了。。。（反正至少大于双通道16G），精度最好。
## 2.总结
其实halcon中提供了锡球检测的例程，里面集成了DFF（depth from focus）算法，且效果较好，速度也快，但是对采集图片的要求较高，换句话说，相机最好是高速相机，高帧率拍出来的过渡较平缓的图，不能有大的跳动，否则很耗时，而且深度信息测算不准确。
